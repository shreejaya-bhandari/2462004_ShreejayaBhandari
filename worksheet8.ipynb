{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6byz7H6MLyh"
      },
      "source": [
        "1. Step -1- Building a Custom Decision Tree with Information Gain:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDBnbNFWMNNC"
      },
      "source": [
        "Custom Built Decision Tree:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HPEkLik4XH9A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class CustomDecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        if len(np.unique(y)) == 1:\n",
        "            return {\"class\": y[0]}\n",
        "\n",
        "        if self.max_depth and depth >= self.max_depth:\n",
        "            return {\"class\": np.bincount(y).argmax()}\n",
        "\n",
        "        best_gain = -1\n",
        "        best_split = None\n",
        "\n",
        "        for feature in range(X.shape[1]):\n",
        "            for threshold in np.unique(X[:, feature]):\n",
        "                left = y[X[:, feature] <= threshold]\n",
        "                right = y[X[:, feature] > threshold]\n",
        "\n",
        "                gain = self._information_gain(y, left, right)\n",
        "\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    best_split = (feature, threshold)\n",
        "\n",
        "        if best_split is None:\n",
        "            return {\"class\": np.bincount(y).argmax()}\n",
        "\n",
        "        feature, threshold = best_split\n",
        "        left_mask = X[:, feature] <= threshold\n",
        "        right_mask = X[:, feature] > threshold\n",
        "\n",
        "        return {\n",
        "            \"feature\": feature,\n",
        "            \"threshold\": threshold,\n",
        "            \"left\": self._build_tree(X[left_mask], y[left_mask], depth+1),\n",
        "            \"right\": self._build_tree(X[right_mask], y[right_mask], depth+1)\n",
        "        }\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        probs = np.bincount(y) / len(y)\n",
        "        return -np.sum(probs * np.log2(probs + 1e-9))\n",
        "\n",
        "    def _information_gain(self, parent, left, right):\n",
        "        return self._entropy(parent) - (\n",
        "            (len(left)/len(parent))*self._entropy(left) +\n",
        "            (len(right)/len(parent))*self._entropy(right)\n",
        "        )\n",
        "\n",
        "    def predict(self, X):\n",
        "        return [self._predict_one(x, self.tree) for x in X]\n",
        "\n",
        "    def _predict_one(self, x, tree):\n",
        "        if \"class\" in tree:\n",
        "            return tree[\"class\"]\n",
        "        if x[tree[\"feature\"]] <= tree[\"threshold\"]:\n",
        "            return self._predict_one(x, tree[\"left\"])\n",
        "        else:\n",
        "            return self._predict_one(x, tree[\"right\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQA_PtmMul6"
      },
      "source": [
        "Step -2- Load and Split the Iris Datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JB0s9tX7MvO-"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooxai6lGNKdv"
      },
      "source": [
        "Step -3- Train and Evaluate a Custom Decision Tree:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYph3EjVM5WU",
        "outputId": "e1d5525d-5008-4286-ca52-9f59736e47cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Tree Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "custom_tree = CustomDecisionTree(max_depth=3)\n",
        "custom_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred_custom = custom_tree.predict(X_test)\n",
        "print(\"Custom Tree Accuracy:\", accuracy_score(y_test, y_pred_custom))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qE6sqSpNQBd"
      },
      "source": [
        "Step -4- Train and Evaluate a Scikit Learn Decision Tree:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHD2f1zWNTaG",
        "outputId": "8cb0cfb2-6f4e-4fc1-a658-67e18343cf64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn Tree Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "sk_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "sk_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred_sk = sk_tree.predict(X_test)\n",
        "print(\"Sklearn Tree Accuracy:\", accuracy_score(y_test, y_pred_sk))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPv-VDNtNf8z"
      },
      "source": [
        "Step -5- Result Comparison:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lJ4aYYRNgmK",
        "outputId": "9db2958d-e25a-4955-85db-bbd7a9b56f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Tree: 1.0\n",
            "Sklearn Tree: 1.0\n"
          ]
        }
      ],
      "source": [
        "print(\"Custom Tree:\", accuracy_score(y_test, y_pred_custom))\n",
        "print(\"Sklearn Tree:\", accuracy_score(y_test, y_pred_sk))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oTSZKfMOc1e"
      },
      "source": [
        "Exercise - Ensemble Methods and Hyperparameter Tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jIBY8h6Odiq"
      },
      "source": [
        "1. Implement Classification Models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFf71E_MOhbJ",
        "outputId": "67b3dbb5-c37e-436e-af03-fda51592f2d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree F1: 0.9314285714285715\n",
            "Random Forest F1: 0.9771428571428572\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "wine = load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Decision Tree F1:\", f1_score(y_test, dt.predict(X_test), average=\"macro\"))\n",
        "print(\"Random Forest F1:\", f1_score(y_test, rf.predict(X_test), average=\"macro\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Hyperparameter Tuning:"
      ],
      "metadata": {
        "id": "TbYQFHsRPZim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "    \"n_estimators\": [50, 100],\n",
        "    \"max_depth\": [None, 10, 20],\n",
        "    \"min_samples_split\": [2, 5]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(RandomForestClassifier(), params, cv=5, scoring=\"f1_macro\")\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGeoSU3qPAT_",
        "outputId": "bad6ff98-7d0d-456c-be0a-9b8aa817ed5c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Implement Regression Model:"
      ],
      "metadata": {
        "id": "Kh8G1Z9lPnAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "dt_reg = DecisionTreeRegressor()\n",
        "rf_reg = RandomForestRegressor()\n",
        "\n",
        "dt_reg.fit(X_train, y_train)\n",
        "rf_reg.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "gkxZ4dEEPBrP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}